{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mNYfL97hADyw",
        "outputId": "6c9c1298-dd38-4b5c-e4dd-368a95afecf4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'whisper'...\n",
            "remote: Enumerating objects: 86, done.\u001b[K\n",
            "remote: Counting objects: 100% (86/86), done.\u001b[K\n",
            "remote: Compressing objects: 100% (84/84), done.\u001b[K\n",
            "remote: Total 86 (delta 49), reused 0 (delta 0), pack-reused 0\u001b[K\n",
            "Unpacking objects: 100% (86/86), done.\n",
            "/content/whisper\n",
            "  Running command git clone -q https://github.com/openai/whisper.git /tmp/pip-req-build-331exbyb\n"
          ]
        }
      ],
      "source": [
        "#@title Install dependencies\n",
        "!git clone https://huggingface.co/spaces/openai/whisper > /dev/null\n",
        "%cd whisper\n",
        "!pip install transformers[sentencepiece] sacremoses > /dev/null\n",
        "!pip install gradio openai TTS > /dev/null\n",
        "!pip install git+https://github.com/openai/whisper.git > /dev/null"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "iDdJnqRC66i-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "30fc2ed5-3e86-4003-db1b-c33cae638a21"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|███████████████████████████████████████| 461M/461M [04:26<00:00, 1.82MiB/s]\n"
          ]
        }
      ],
      "source": [
        "#@title Load libraries and models (set your OpenAI API key here)\n",
        "import os\n",
        "import gradio as gr\n",
        "import whisper\n",
        "import openai\n",
        "\n",
        "openai.api_key = \"****\"\n",
        "\n",
        "task = \"translate\"\n",
        "max_context_len = 1000\n",
        "model = 'text-davinci-003'\n",
        "\n",
        "speech2text_model = whisper.load_model(\"small\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eeXq_aP-JmWu"
      },
      "source": [
        "# CHARACTER DEFINITION"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y1MeSgAGLEjS"
      },
      "outputs": [],
      "source": [
        "CHARACTER = 'PIRATA'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3C8cBUtNL9L5"
      },
      "outputs": [],
      "source": [
        "\n",
        "if CHARACTER == 'PIRATA':\n",
        "  context = '''This is a conversational adventure game. You play the role of a pirate that has travelled around the world and lived many exciting adventures.\n",
        "  You are talking with a child through a magical device. Entertain him talking about your many adventures. Some data about your character:\n",
        "  Name: Jon\n",
        "  Age: thirty six\n",
        "  Profession: pirate\n",
        "  Some of your adventures: once you killed a sea dragon. You married a mermaid. Your ship was attacked by a ghost ship. You met a god.\n",
        "  (Perform a single brief conversation turn each time playing your character. Express all numbers as a literal)'''\n",
        "\n",
        "  character_name = 'PIRATA'\n",
        "\n",
        "  intro = \"Hola! ¿Puedes oirme?\"\n",
        "\n",
        "  fallback = 'Oh, no, no puedo oirte!'\n",
        "elif CHARACTER == 'SANTA':\n",
        "  context = '''This is a conversational adventure game. You play the role of santa claus. You are talking with a child through a magical device.\n",
        "  Entertain him talking about your many adventures and the presents you are bringing him this year.\n",
        "  (Perform a single conversation turn each time playing your character. Express all numbers as a literal)'''\n",
        "\n",
        "  character_name = 'SANTA'\n",
        "\n",
        "  intro = \"Hola! ¿Puedes oirme?\"\n",
        "\n",
        "  fallback = 'Oh, no, no puedo oirte!'\n",
        "elif CHARACTER == 'DRAGON':\n",
        "  context = '''This is a conversational adventure game. You play the role of a dragon that lives inside a mountain keeping an enormous gold treasure.\n",
        "  You are talking with a child through a magical device. Entertain him talking about your many adventures and treasures.\n",
        "  (Perform a single conversation turn each time playing your character. Express all numbers as a literal)'''\n",
        "\n",
        "  character_name = 'DRAGON'\n",
        "\n",
        "  intro = \"Hola! ¿Puedes oirme?\"\n",
        "\n",
        "  fallback = 'Oh, no, no puedo oirte!'\n",
        "elif CHARACTER == 'ROBOT':\n",
        "  context = '''This is a conversational adventure game. You play the role of a robot from a distant planet. You are talking with a child with your alien technology.\n",
        "  Entertain him talking about your homeworld and your space travels:\n",
        "  (Perform a single conversation turn each time playing your character. Express all numbers as a literal)'''\n",
        "\n",
        "  character_name = 'ROBOT'\n",
        "\n",
        "  intro = \"Hola! ¿Puedes oirme?\"\n",
        "\n",
        "  fallback = 'Oh, no, no puedo oirte!'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cwW5-bODJYIe"
      },
      "outputs": [],
      "source": [
        "history = character_name + \": \" + intro\n",
        "historia = character_name + \": \" + intro"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YRwYAa2LBU1m",
        "outputId": "2b21cda0-88e7-4cda-9acb-54f31376065f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " > Downloading model to /root/.local/share/tts/tts_models--es--css10--vits\n",
            "100% 101M/101M [00:24<00:00, 4.05MiB/s]\n",
            " > Model's license - bsd-3-clause\n",
            " > Check https://opensource.org/licenses for more info.\n",
            " > Using model: vits\n",
            " > Setting up Audio Processor...\n",
            " | > sample_rate:22050\n",
            " | > resample:False\n",
            " | > num_mels:80\n",
            " | > log_func:np.log10\n",
            " | > min_level_db:0\n",
            " | > frame_shift_ms:None\n",
            " | > frame_length_ms:None\n",
            " | > ref_level_db:None\n",
            " | > fft_size:1024\n",
            " | > power:None\n",
            " | > preemphasis:0.0\n",
            " | > griffin_lim_iters:None\n",
            " | > signal_norm:None\n",
            " | > symmetric_norm:None\n",
            " | > mel_fmin:0\n",
            " | > mel_fmax:None\n",
            " | > pitch_fmin:None\n",
            " | > pitch_fmax:None\n",
            " | > spec_gain:20.0\n",
            " | > stft_pad_mode:reflect\n",
            " | > max_norm:1.0\n",
            " | > clip_norm:True\n",
            " | > do_trim_silence:False\n",
            " | > trim_db:60\n",
            " | > do_sound_norm:False\n",
            " | > do_amp_to_db_linear:True\n",
            " | > do_amp_to_db_mel:True\n",
            " | > do_rms_norm:False\n",
            " | > db_level:None\n",
            " | > stats_path:None\n",
            " | > base:10\n",
            " | > hop_length:256\n",
            " | > win_length:1024\n",
            " > initialization of speaker-embedding layers.\n",
            " > initialization of language-embedding layers.\n",
            " > Text: Hola! ¿Puedes oirme?\n",
            " > Text splitted to sentences.\n",
            "['Hola!', '¿Puedes oirme?']\n",
            "['<BLNK>', '¿', '<BLNK>', 'p', '<BLNK>', 'u', '<BLNK>', 'e', '<BLNK>', 'd', '<BLNK>', 'e', '<BLNK>', 's', '<BLNK>', ' ', '<BLNK>', 'o', '<BLNK>', 'i', '<BLNK>', 'r', '<BLNK>', 'm', '<BLNK>', 'e', '<BLNK>', '?', '<BLNK>']\n",
            " [!] Character '¿' not found in the vocabulary. Discarding it.\n",
            " > Processing time: 0.8572385311126709\n",
            " > Real-time factor: 0.2882825404318325\n",
            " > Saving output to intro.wav\n"
          ]
        }
      ],
      "source": [
        "!tts --text \"$intro\" --out_path \"intro.wav\" --model_name \"tts_models/es/css10/vits\" "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VdHNz3juJsz3"
      },
      "source": [
        "# RUN APP"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 651
        },
        "id": "SPL_x9jX741h",
        "outputId": "e1067c08-61a0-4e7e-f8e5-619e584c08f5",
        "cellView": "form"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/gradio/layouts.py:75: UserWarning: mobile_collapse is no longer supported.\n",
            "  warnings.warn(\"mobile_collapse is no longer supported.\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Colab notebook detected. To show errors in colab notebook, set `debug=True` in `launch()`\n",
            "Note: opening Chrome Inspector may crash demo inside Colab notebooks.\n",
            "\n",
            "To create a public link, set `share=True` in `launch()`.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "(async (port, path, width, height, cache, element) => {\n",
              "                        if (!google.colab.kernel.accessAllowed && !cache) {\n",
              "                            return;\n",
              "                        }\n",
              "                        element.appendChild(document.createTextNode(''));\n",
              "                        const url = await google.colab.kernel.proxyPort(port, {cache});\n",
              "\n",
              "                        const external_link = document.createElement('div');\n",
              "                        external_link.innerHTML = `\n",
              "                            <div style=\"font-family: monospace; margin-bottom: 0.5rem\">\n",
              "                                Running on <a href=${new URL(path, url).toString()} target=\"_blank\">\n",
              "                                    https://localhost:${port}${path}\n",
              "                                </a>\n",
              "                            </div>\n",
              "                        `;\n",
              "                        element.appendChild(external_link);\n",
              "\n",
              "                        const iframe = document.createElement('iframe');\n",
              "                        iframe.src = new URL(path, url).toString();\n",
              "                        iframe.height = height;\n",
              "                        iframe.allow = \"autoplay; camera; microphone; clipboard-read; clipboard-write;\"\n",
              "                        iframe.width = width;\n",
              "                        iframe.style.border = 0;\n",
              "                        element.appendChild(iframe);\n",
              "                    })(7860, \"/\", \"100%\", 500, false, window.element)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "#@title Chat app\n",
        "\n",
        "def process_gpt3_response(raw_response):\n",
        "    global fallback\n",
        "    global character_name\n",
        "    \n",
        "    answer_lines = raw_response[\"choices\"][0]['text'].replace(character_name + \":\",\"\").strip().split('\\n')\n",
        "\n",
        "    answer = next((x for x in answer_lines if len(x) > 3), fallback)\n",
        "\n",
        "    return answer\n",
        "\n",
        "def inference(audio):\n",
        "\n",
        "    global history\n",
        "    # global historia\n",
        "    \n",
        "    previous_conv = history\n",
        "    \n",
        "    audio = whisper.load_audio(audio)\n",
        "    audio = whisper.pad_or_trim(audio)\n",
        "    \n",
        "    mel = whisper.log_mel_spectrogram(audio).to(speech2text_model.device)\n",
        "    \n",
        "    # _, probs = speech2text_model.detect_language(mel)\n",
        "    \n",
        "    options = whisper.DecodingOptions(fp16 = False) #, task = task)\n",
        "    result = whisper.decode(speech2text_model, mel, options)\n",
        "\n",
        "    updated_conv = previous_conv + '\\nNIÑO: ' + result.text.replace(\"\\n\", \"\")\n",
        "    prompt = updated_conv\n",
        "\n",
        "    if len(prompt) > max_context_len:\n",
        "        prompt = prompt[-max_context_len:]\n",
        "\n",
        "    prompt = context + '\\n' + prompt + '\\n'\n",
        "    \n",
        "    gpt3_response = openai.Completion.create(\n",
        "      engine=model,\n",
        "      prompt=prompt,\n",
        "      max_tokens=150,\n",
        "      temperature = 0.8,\n",
        "      top_p = 1,\n",
        "      echo = False,\n",
        "      n = 1\n",
        "    )\n",
        "\n",
        "    answer = process_gpt3_response(gpt3_response)\n",
        "\n",
        "    !tts --text \"$answer\" --out_path \"out.wav\" --model_name \"tts_models/es/css10/vits\"\n",
        "    \n",
        "    updated_conv = updated_conv + '\\n' + answer\n",
        "    history = updated_conv\n",
        "    # historia = historia + '\\nNIÑO: ' + result.text + answer\n",
        "    print(f'Previous conv: {previous_conv}')\n",
        "    print(f'Transcripción: {result.text}')\n",
        "    print(f'Prompt: {prompt}')\n",
        "    print(f'Respuesta: {gpt3_response}')\n",
        "    print(updated_conv)\n",
        "    return answer, \"out.wav\"\n",
        "\n",
        "block = gr.Blocks()\n",
        "\n",
        "with block:\n",
        "    with gr.Group():\n",
        "        with gr.Box():\n",
        "            with gr.Row().style(mobile_collapse=False, equal_height=True):\n",
        "                audio = gr.Audio(\n",
        "                    label=\"Input Audio\",\n",
        "                    show_label=False,\n",
        "                    source=\"microphone\",\n",
        "                    type=\"filepath\"\n",
        "                )\n",
        "\n",
        "                btn = gr.Button(\"Enviar\")\n",
        "        with gr.Box():\n",
        "          text_answer = gr.Textbox(show_label=False, elem_id=\"result-textarea\")\n",
        "          audio_answer = gr.Audio(label=\"Output Audio\", value = \"intro.wav\")\n",
        "                \n",
        "        btn.click(inference, inputs=[audio], outputs=[text_answer, audio_answer])\n",
        "\n",
        "block.launch(debug=False)"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "UypmBU3nUNOL"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}